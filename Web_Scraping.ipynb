{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMEcio+OwxFNzotekqKoCnU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Web Scraping from CareerBliss**\n","\n","**Group Members:** Michael DeMasi, Katherine Yang, Tolani Oshinusi, Jeremy Cho\n","\n","Based on our research, we will scrape employee reviews from mulitple high/low attrition companies.\n","\n","- High Attrition Companies:\n","  - Apple\n","  - Amazon\n","  - Facebook\n","  - Tesla\n","  - AMD\n","  - ServiceNow\n","  - Mastercard\n","  - Abbot Laboratories\n","\n","- Low Attrition Companies\n","  - Conoco Phillips\n","  - Chevron\n","  - Lockheed Martin\n","  - Comcast\n","  - Boeing\n","  - ExxonMobil\n","  - Progressive\n","  - Honeywell"],"metadata":{"id":"KDyausOsz-UN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sykg-NNszt08"},"outputs":[],"source":["# Imports for web scraping\n","import requests\n","from bs4 import BeautifulSoup\n","import time\n","import pandas as pd"]},{"cell_type":"code","source":["''' WARNING: This cell takes about 30 minutes to run, the csv has been previously generated for use in the main notebook! '''\n","''' Perform web scraping to collect reviews from CareerBliss and generate a dataframe.'''\n","\n","# initialize a dataframe to store the scraped data\n","reviews_df = pd.DataFrame(columns=[\"review_id\", \"company_name\", \"job_title\", \"company_id\", \"job_title_id\", \"review\", \"attrition_level\"])\n","\n","# companies to consider based on research\n","high_attrition_companies = [\"apple\", \"amazon\", \"facebook\", \"tesla-motors\", \"amd\", \"servicenow\", \"mastercard\", \"abbott-laboratories\"]\n","low_attrition_companies = [\"conocophillips\", \"chevron\", \"lockheed-martin\", \"comcast\", \"boeing\", \"exxonmobil\", \"progressive\", \"honeywell\"]\n","\n","# companies with their maximum page numbers on careerbliss\n","companies = {\n","    \"apple\": 49,\n","    \"amazon\": 51,\n","    \"facebook\": 5,\n","    \"tesla-motors\": 10,\n","    \"amd\": 17,\n","    \"servicenow\": 2,\n","    \"mastercard\": 4,\n","    \"abbott-laboratories\": 33,\n","    \"conocophillips\": 6,\n","    \"chevron\": 21,\n","    \"lockheed-martin\": 87,\n","    \"comcast\": 63,\n","    \"boeing\": 59,\n","    \"exxonmobil\": 16,\n","    \"progressive\": 5,\n","    \"honeywell\": 35\n","}\n","\n","headers = {\n","    \"-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n","}\n","\n","# Iterate through each company and their pages\n","for company, max_pages in companies.items():\n","  base_url = f\"https://www.careerbliss.com/{company}/reviews/\"\n","  print(company)\n","\n","  for page in range(max_pages):\n","    print(page)\n","    if page == 0:\n","        url = base_url\n","    else:\n","      url = f\"{base_url}?page={page}\"\n","    response = requests.get(url, headers=headers)\n","\n","    if response.status_code != 200:\n","        print(f\"Failed to fetch page {page}: Status code {response.status_code}\")\n","        break\n","\n","    soup = BeautifulSoup(response.content, \"html.parser\")\n","    reviews = soup.find_all(\"div\", class_=\"company-reviews\")\n","\n","    # Extract the required fields from each review block\n","    for review in reviews:\n","        try:\n","            # Capture all elements from the HTML page and handle inconsistancies\n","            review_id = review.find(\"a\", class_=\"job-title header5 twocentChromeExt\")\n","            if review_id:\n","                review_id = review_id.get(\"data-reviewid\", None)\n","            company_name = review.find(\"a\", class_=\"job-title header5 twocentChromeExt\")\n","            if company_name:\n","                company_name = company_name.get(\"data-company\", None)\n","            job_title = review.find(\"a\", class_=\"job-title header5 twocentChromeExt\")\n","            if job_title:\n","                job_title = job_title.get(\"data-jobtitle\", None)\n","            company_id = review.find(\"a\", class_=\"job-title header5 twocentChromeExt\")\n","            if company_id:\n","                company_id = company_id.get(\"data-companyid\", None)\n","            job_title_id = review.find(\"a\", class_=\"job-title header5 twocentChromeExt\")\n","            if job_title_id:\n","                job_title_id = job_title_id.get(\"data-jobtitleid\", None)\n","            review_text = review.find(\"p\", class_=\"comments foggy\")\n","            if review_text:\n","                review_text = review_text.text.strip()\n","            if company in high_attrition_companies:\n","                attrition_level = \"high\"\n","            else:\n","                attrition_level = \"low\"\n","\n","            # Append to DataFrame if following fields are present\n","            if review_id and company and job_title and company_id and job_title_id and review_text:\n","                reviews_df = pd.concat([\n","                    reviews_df,\n","                    pd.DataFrame([{\n","                        \"review_id\": review_id,\n","                        \"company_name\": company_name,\n","                        \"job_title\": job_title,\n","                        \"company_id\": company_id,\n","                        \"job_title_id\": job_title_id,\n","                        \"review\": review_text,\n","                        \"attrition_level\": attrition_level\n","                    }])\n","                ], ignore_index=True)\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","\n","    # add delay between requests to prevent being blocked\n","    time.sleep(1)\n","\n","# Save the DataFrame to a CSV file\n","reviews_df.to_csv(\"careerbliss_reviews.csv\", index=False)"],"metadata":{"id":"jcc6uI800AUe"},"execution_count":null,"outputs":[]}]}